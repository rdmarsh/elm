import hashlib
import re

import base64
import time
import hmac

import logging
import json
from collections import defaultdict
from pygments import highlight, lexers, formatters
from packaging import version
import pandas as pd
from tabulate import tabulate
import click
import htmlmin
import requests

log = logging.getLogger(__name__)

def engine(elm, **kwargs):
    """This is common engine for all commands"""

    logging.debug('passed kwargs: %s', kwargs)
    logging.info('elm.command: %s', elm.command)
    logging.info('elm.path: %s', elm.path)
    logging.info('elm.format: %s', elm.format)
    logging.info('elm.noheaders: %s', elm.noheaders)
    logging.info('elm.index: %s', elm.index)
    logging.info('elm.filename: %s', elm.filename)
    logging.info('elm.head: %s', elm.head)
    logging.info('elm.foot: %s', elm.foot)

    # ben magic, throw away False and Empty flags (also zeros!)
    flags = {k: v for k, v in kwargs.items() if v}
    logging.debug('passed flags: %s', flags)

    #set size to max (1000) if size is 0
    #0 values are removed by ben magic above
    if 'size' in kwargs and kwargs['size'] == 0:
        logging.debug('kwargs[\'size\']: %s', kwargs['size'])
        logging.debug('size set to 0, changing to 1000 for max size allowed by api')
        flags['size'] = 1000
        logging.debug('kwargs[\'size\']: %s', kwargs['size'])

    #Request Info
    httpVerb ='GET'
    logging.debug('httpVerb: %s', httpVerb)

    #construct path based on passed attributes (path values)
    # find placeholders between {} and collect in attributes var for below
    attributes = re.findall(r'\{([A-Za-z0-9_]+?)\}',elm.path)
    logging.debug('attributes: %s', attributes)

    #for every attribute in the path found above, swap in the value and construct the path for the url
    for attribute in attributes:
        logging.debug('ins "%s" value "%s" into %s', attribute, flags[attribute], elm.path)
        elm.path = elm.path.replace("{" + attribute + "}", str(flags[attribute]))

        # remove the attribute from flags cause we've handle it
        logging.debug('del "%s" from flags', attribute)
        del flags[attribute]

    #todo: check for any remaining attributes by looking for {} in elm.path
    #logging.warning('not all attributes replaced in path: %s', elm.path)

    logging.debug('elm.path attributes: %s', elm.path)
    logging.debug('remaining flags: %s', flags)

    #construct resourcePath
    resourcePath = elm.path
    logging.debug('resourcePath: %s', resourcePath)

    #construct URL
    url = 'https://'+ elm.account_name +'.logicmonitor.com/santaba/rest' + resourcePath
    logging.debug('url: %s', url)

    #construct queryParams
    queryParams = ''

    #turn flags into queryParams key values
    for flag in flags:
        logging.debug('flag: %s', flag)
        logging.debug('flags[flag]: %s', flags[flag])
        queryParams += '&' + flag + '=' + str(flags[flag])

    logging.debug('queryParams: %s', queryParams)

    data = ''
    logging.debug('data: %s', data)

    #Get current time in milliseconds
    epoch = str(int(time.time() * 1000))
    logging.debug('epoch: %s', epoch)

    #Concatenate Request details
    requestVars = httpVerb + epoch + data + resourcePath
    logging.debug('requestVars: %s', requestVars)

    #Construct signature
    hmac1 = hmac.new(elm.access_key.encode(),msg=requestVars.encode(),digestmod=hashlib.sha256).hexdigest()
    signature = base64.b64encode(hmac1.encode())

    #Construct html headers
    auth = 'LMv1 ' + elm.access_id + ':' + signature.decode() + ':' + epoch
    # dont show this as it has the api auth details
    #logging.info('auth: %s', auth)
    headers = {'Content-Type':'application/json','Authorization':auth,'X-Version':'{{ apiversion }}'}
    # dont show this as it has the api auth details
    #logging.info('headers: %s', headers)

    #Make request
    try:
        response = requests.get(url, data=data, headers=headers, params=queryParams)
        # Safely access headers using .get() to avoid KeyError if a header is missing
        logging.debug('response.headers.X-Rate-Limit-Limit: %s', response.headers.get('X-Rate-Limit-Limit', 'Header not found'))
        logging.debug('response.headers.X-Rate-Limit-Remaining: %s', response.headers.get('X-Rate-Limit-Remaining', 'Header not found'))
        logging.debug('response.headers.X-Rate-Limit-Window: %s', response.headers.get('X-Rate-Limit-Window', 'Header not found'))
        # Check for HTTP errors
        response.raise_for_status()
    except requests.RequestException as e:
        # Print error messages with relevant details
        click.secho('Error: request failed', fg='red', err=True)
        click.secho(f'Command: {elm.command}', fg='red', err=True)
        click.secho(f'Path: {elm.path}', fg='red', err=True)
        click.secho(f'Flags: {str(flags)}', fg='red', err=True)
        logging.error('request failed: %s', e)
        sys.exit(1)  # Exit with a non-zero status code

    logging.info('response.url: %s', response.url)
    logging.info('response.status_code: %s', response.status_code)
    logging.debug('response.content: %s', response.content)

    # do I need this or is it covered by above raise for status?
    if not response:
        logging.warning('not 200 status code: %s', response.status_code)
        click.secho('Warning: not 200 status code', fg='yellow', err=True)

    # where should this go, do we need it?
    response.encoding = 'utf-8'

    #for future use, currently not finished
    if elm.export:
        logging.debug('elm.export: %s', elm.export)
        logging.debug('elm.config_file: %s', elm.config_file)
        logging.debug('elm.path: %s', elm.path)
        logging.debug('elm.flags: %s', elm.flags)
        export(elm.export, elm.config_file, elm.command, elm.path, flags)

    #obj = response.content
    obj = response.json()
    #obj = response.content.decode('utf-8')

    #used for queries by id, which only return one item
    if 'items' not in obj:
        logging.debug('items not in obj, setting to defaults')
        obj = {
            "total": 1,
            "items": [obj],
            "searchId": None,
            "isMin": False
        }

    logging.info('total records: %s', obj.get('total', None))
    logging.debug('searchId: %s', obj.get('searchId', None))
    logging.debug('isMin: %s', obj.get('isMin', None))
    logging.debug('obj: %s', obj)

    if elm.format == "api":
        click.echo(response.url)
        click.echo("Authorization: " + auth)
    elif 'total' in flags:
        logging.debug('total is a flag, showing total instead')
        click.echo(obj['total'])
    elif 'count' in flags:
        logging.debug('count is a flag, showing count instead')
        click.echo(len(obj['items']))
    else:
        output(obj['items'], elm.command, elm.filename, elm.format, elm.noheaders, elm.index, elm.head, elm.foot)

        #give a warning if there are more records not shown
        if 'size' in flags and obj['total'] > flags['size']:
            click.secho('Warning: size limit is less than total records,'
                        ' there is data you are not seeing.',
                        fg='yellow', err=True)

def output(items, command, filename='-', format='json', noheaders=False, index=False, head='', foot=''):
    df = pd.DataFrame(items)
    logging.debug('df: %s', df)

    if not df.empty:
        pd.set_option('display.max_columns', 0)
        pd.set_option('display.max_colwidth', 0)

        #todo: convert any columns with an subdict

        #number index from 1 instead of 0
        df.index = df.index + 1

        logging.debug('format: %s', format)
        logging.debug('noheaders: %s', noheaders)
        logging.debug('index: %s', index)
        logging.debug('dtypes:\n%s', df.dtypes)

        #set headers to an empty array, this is for passing
        #to tabulate as it doesn't understand header=False
        if noheaders:
            colheads=[]
        else:
            colheads=df.columns

        logging.debug('colheads: %s', colheads)

        if format == 'csv':
            output = df.to_csv(header=noheaders, index=index)
            #to_csv adds a blank line to the end, this is to remove it
            output = output[:-1]
        elif format == 'html':
            output = htmlmin.minify(df.to_html(header=noheaders, index=index, render_links=True, escape=False), remove_empty_space=True)
        elif format == 'prettyhtml':
            output = highlight(df.to_html(header=noheaders, index=index, render_links=True, escape=False), lexers.HtmlLexer(), formatters.TerminalFormatter())
        elif format == 'jira':
            #next line is a workaround for unescaped pipes bug: https://github.com/astanin/python-tabulate/issues/241
            df = df.map(lambda s: s.replace('|','\\|') if isinstance(s, str) else s)
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="jira", floatfmt='.0f')
        elif format == 'json':
            output = json.dumps({command: items})
        elif format == 'prettyjson':
            formatted_json=json.dumps({command: items}, sort_keys=True, indent=2)
            colorful_json = highlight(formatted_json, lexers.JsonLexer(), formatters.TerminalFormatter())
            output = colorful_json.rstrip("\n")
        elif format == 'xml':
            output = df.to_xml(pretty_print=False)
        elif format == 'prettyxml':
            output = df.to_xml(pretty_print=True)
        elif format == 'gfm':
            #next line is a workaround for unescaped pipes bug: https://github.com/astanin/python-tabulate/issues/241
            df = df.map(lambda s: s.replace('|','\\|') if isinstance(s, str) else s)
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="github", floatfmt='.0f')
        elif format == 'latex':
            output = df.to_latex(header=noheaders, index=index)
        elif format == 'md':
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="simple", floatfmt='.0f')
        elif format == 'pipe':
            #next line is a workaround for unescaped pipes bug: https://github.com/astanin/python-tabulate/issues/241
            df = df.map(lambda s: s.replace('|','\\|') if isinstance(s, str) else s)
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="pipe", floatfmt='.0f')
        elif format == 'rst':
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="rst", floatfmt='.0f')
        elif format == 'tab':
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="simple", floatfmt='.0f')
        elif format == 'raw':
            output = items
        else:
            # fail to plain txt
            output = tabulate(df, headers=colheads, showindex=index, tablefmt="plain", floatfmt='.0f')

        output_file = click.open_file(filename, mode='w')

        if head:
            output = head + '\n\n' + output

        if foot:
            output = output + '\n\n' + foot

        click.echo(output, file=output_file)
    elif len(df.columns) == 0 and len(df.index) > 0:
        click.secho('Error: no valid fields selected', fg='red', err=True)
    else:
        click.secho('Warning: no data found', fg='yellow', err=True)

#for future use, currently not finished
def export(export, config_file, command, path, flags=""):
    '''export python query to file'''
    file_loader = FileSystemLoader('elm')
    env = Environment(loader=file_loader)
    template = env.get_template('save_query.py.j2')
    output = template.render(config_file=config_file, command=command, path=path, flags=flags)
    export.write(output)

def validate_filter(ctx, param, filters):
    if filters:
        filters_fmtchkd=[]
        logging.debug('filters: %s', filters)
        logging.debug('filters_fmtchkd: %s', filters_fmtchkd)
        #split filters by commas except if they're proceeded by a backslash
        for filter in re.split(r"(?<!\\),", filters):
            #now remove the backslash we used to protect the comma from split above
            logging.debug(r'filter (inc \,): %s', filter)
            filter = filter.replace(r'\,',',')
            logging.debug(r'filter (rem \,): %s', filter)
            try:
                field, operator, value = re.split(r'(>\:|<\:|>|<|\:|\!~|\!\:|~)', filter, 1)

                logging.debug('field: %s', field)
                logging.debug('operator: %s', operator)
                logging.debug('value: %s', value)
                #filter needs quotes around the value to work for strings
                #this saves the user from having to escape quotes on the cli
                #ints are not unaffected, so do it for everything
                value = '"' + value + '"'
                logging.debug('value: %s', value)
                filters_fmtchkd.append(field + operator + value)
                logging.debug('filters_fmtchkd: %s', filters_fmtchkd)
            except ValueError:
                raise click.BadParameter("format must be 'FIELD[>:,<:,>,<,!:,:,~,!~]VALUE'")

        return ",".join(filters_fmtchkd)
